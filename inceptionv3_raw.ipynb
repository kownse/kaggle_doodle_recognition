{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "import ast\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras.legacy import interfaces\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from data import *\n",
    "from keras_helper import *\n",
    "\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT = 49673580\n",
    "EPOCHS = 50\n",
    "size = 75\n",
    "batchsize = 640\n",
    "lw = 2\n",
    "channel = 1\n",
    "STEPS = TOT / EPOCHS / batchsize / 3\n",
    "NCATS = 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_input(x):\n",
    "#     x /= 127.5\n",
    "#     x -= 1.\n",
    "#     return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 75, 75, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 37, 37, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 35, 35, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 35, 32)   96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 35, 35, 32)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 64)   192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 17, 17, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 17, 17, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 17, 17, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 17, 17, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 15, 15, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 15, 15, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 15, 15, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 192)    0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 7, 7, 64)     192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 7, 7, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 7, 7, 48)     9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 96)     55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 7, 7, 48)     144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 7, 7, 96)     288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 7, 7, 48)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 7, 7, 96)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 7, 7, 192)    0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 7, 7, 64)     12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 7, 7, 64)     76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 7, 7, 96)     82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 7, 7, 32)     6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 7, 7, 64)     192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 7, 7, 64)     192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 7, 7, 96)     288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 7, 7, 32)     96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 7, 7, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 7, 7, 64)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 7, 7, 96)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 7, 7, 32)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 7, 7, 256)    0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 7, 64)     192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 7, 7, 64)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 7, 7, 48)     12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 7, 7, 96)     55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 7, 7, 48)     144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 7, 7, 96)     288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 7, 7, 48)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 7, 7, 96)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 7, 7, 256)    0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 7, 7, 64)     16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 7, 7, 64)     76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 7, 7, 96)     82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 7, 7, 64)     16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 7, 7, 64)     192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 7, 7, 64)     192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 7, 7, 96)     288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 7, 7, 64)     192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 7, 7, 64)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 7, 7, 64)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 7, 7, 96)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 7, 7, 64)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 7, 7, 288)    0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 7, 7, 64)     192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 7, 7, 64)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 7, 7, 48)     13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 7, 7, 96)     55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 7, 7, 48)     144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 7, 7, 96)     288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 7, 7, 48)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 7, 7, 96)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 288)    0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 7, 7, 64)     18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 7, 7, 64)     76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 7, 7, 96)     82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 64)     18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 7, 7, 64)     192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 7, 7, 64)     192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 7, 7, 96)     288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 64)     192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 7, 7, 64)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 7, 7, 64)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 7, 7, 96)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 64)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 7, 7, 288)    0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 7, 7, 64)     18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 7, 7, 64)     192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 7, 7, 64)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 3, 3, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 3, 3, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 3, 3, 384)    1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 3, 3, 96)     288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 384)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 96)     0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 3, 3, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 3, 3, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 3, 3, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 3, 3, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 3, 3, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 3, 3, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 3, 3, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 3, 3, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 3, 3, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 3, 3, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 3, 3, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 3, 3, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 3, 3, 128)    384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 3, 3, 128)    384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 128)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 3, 3, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 3, 3, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 3, 3, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 3, 3, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 3, 3, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 3, 3, 192)    576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 3, 3, 192)    576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 3, 3, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 3, 3, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 192)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 192)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 3, 3, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 3, 3, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 3, 3, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 3, 3, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 3, 3, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 3, 3, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 3, 3, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 3, 3, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 3, 3, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 3, 3, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 3, 3, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 3, 3, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 3, 3, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 3, 3, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 3, 3, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 3, 3, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 3, 3, 160)    480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 3, 3, 160)    480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 3, 3, 160)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 3, 3, 160)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 3, 3, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 3, 3, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 3, 3, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 3, 3, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 3, 3, 192)    576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 3, 3, 192)    576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 3, 3, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 3, 3, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 3, 3, 192)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 3, 3, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 3, 3, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 3, 3, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 3, 3, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 3, 3, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 3, 3, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 3, 3, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 3, 3, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 3, 3, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 3, 3, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 3, 3, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 3, 3, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 3, 3, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 3, 3, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 3, 3, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 3, 3, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 3, 3, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 3, 3, 160)    480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 3, 3, 160)    480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 3, 3, 160)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 3, 3, 160)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 3, 3, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 3, 3, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 3, 3, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 3, 3, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 3, 3, 192)    576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 3, 3, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 3, 3, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 3, 3, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 3, 3, 192)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 3, 3, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 3, 3, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 3, 3, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 3, 3, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 3, 3, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 3, 3, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 3, 3, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 3, 3, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 3, 3, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 3, 3, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 3, 3, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 3, 3, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 3, 3, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 3, 3, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 3, 3, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 3, 3, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 3, 3, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 3, 3, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 3, 3, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 3, 3, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 3, 3, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 3, 3, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 3, 3, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 3, 3, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 3, 3, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 3, 3, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 3, 3, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 3, 3, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 3, 3, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 3, 3, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 3, 3, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 3, 3, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 3, 3, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 3, 3, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 3, 3, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 3, 3, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 3, 3, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 3, 3, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 1, 1, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 1, 1, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 1, 1, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 1, 1, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 1, 1, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 1, 1, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 1, 1, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 1, 1, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 1, 1, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1, 1, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 1, 1, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 1, 1, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 1, 1, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 1, 1, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1, 1, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 1, 1, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 1, 1, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 1, 1, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 1, 1, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 1, 1, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 1, 1, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 1, 1, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 1, 1, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 1, 1, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 1, 1, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 1, 1, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 1, 1, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1, 1, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1, 1, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 1, 1, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 1, 1, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 1, 1, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1, 1, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 1, 1, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1, 1, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 1, 1, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 1, 1, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 1, 1, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 1, 1, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 1, 1, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 1, 1, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 1, 1, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 1, 1, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 1, 1, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 1, 1, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 1, 1, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 1, 1, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 1, 1, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 1, 1, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 1, 1, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 1, 1, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 1, 1, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 1, 1, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 1, 1, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 1, 1, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 1, 1, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 1, 1, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 1, 1, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 1, 1, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 1, 1, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 1, 1, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 1, 1, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 1, 1, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 1, 1, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 1, 1, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 1, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 1, 1, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 1, 1, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 340)          696660      avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,498,868\n",
      "Trainable params: 22,464,436\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# base_model = MobileNet(input_shape=(size, size, 3), alpha=1., weights='imagenet', include_top=False)\n",
    "# x = base_model.output\n",
    "# # x = GlobalAveragePooling2D()(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(512)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(64)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# predictions = Dense(NCATS, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model = InceptionV3(input_shape=(size, size, 1), weights=None, classes=NCATS)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('../input/valid.csv')\n",
    "x_valid = df_to_image_array_xd(valid_df, size, lw=lw, preprocess_input=preprocess_input, channel=channel)\n",
    "y_valid = keras.utils.to_categorical(valid_df.word, num_classes=NCATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34000, 75, 75, 1) (34000, 340)\n",
      "Validation array memory 0.71 GB\n"
     ]
    }
   ],
   "source": [
    "print(x_valid.shape, y_valid.shape)\n",
    "print('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image_generator_xd(size=size, batchsize=batchsize, lw=lw, \n",
    "                                   preprocess_input=preprocess_input,\n",
    "                                  channel=channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = 'inceptionv3_raw_head'\n",
    "fold = 9\n",
    "callbks = [\n",
    "    ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5,\n",
    "                      min_delta=0.005, mode='max', cooldown=3, verbose=1),\n",
    "    callbacks.ModelCheckpoint(\"./models/{}{}.model\".format(model_prefix, size),\n",
    "                                monitor='val_categorical_accuracy', \n",
    "                                mode = 'max', save_best_only=True, verbose=1),\n",
    "    callbacks.TensorBoard(log_dir='./log/{}{}'.format(model_prefix, size)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "518/517 [==============================] - 171s 330ms/step - loss: 3.6799 - categorical_crossentropy: 3.6799 - categorical_accuracy: 0.2168 - top_3_accuracy: 0.3767 - val_loss: 4.0579 - val_categorical_crossentropy: 4.0579 - val_categorical_accuracy: 0.2261 - val_top_3_accuracy: 0.4190\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.22615, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 2/50\n",
      "518/517 [==============================] - 156s 302ms/step - loss: 2.4380 - categorical_crossentropy: 2.4380 - categorical_accuracy: 0.4256 - top_3_accuracy: 0.6424 - val_loss: 9.6372 - val_categorical_crossentropy: 9.6372 - val_categorical_accuracy: 0.0348 - val_top_3_accuracy: 0.1256\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.22615\n",
      "Epoch 3/50\n",
      "518/517 [==============================] - 158s 305ms/step - loss: 2.0419 - categorical_crossentropy: 2.0419 - categorical_accuracy: 0.5095 - top_3_accuracy: 0.7222 - val_loss: 2.2756 - val_categorical_crossentropy: 2.2756 - val_categorical_accuracy: 0.4692 - val_top_3_accuracy: 0.6918\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.22615 to 0.46921, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 4/50\n",
      "518/517 [==============================] - 156s 302ms/step - loss: 1.9038 - categorical_crossentropy: 1.9038 - categorical_accuracy: 0.5406 - top_3_accuracy: 0.7481 - val_loss: 3.7191 - val_categorical_crossentropy: 3.7191 - val_categorical_accuracy: 0.3813 - val_top_3_accuracy: 0.6431\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.46921\n",
      "Epoch 5/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.6862 - categorical_crossentropy: 1.6862 - categorical_accuracy: 0.5873 - top_3_accuracy: 0.7866 - val_loss: 1.8402 - val_categorical_crossentropy: 1.8402 - val_categorical_accuracy: 0.5505 - val_top_3_accuracy: 0.7549\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.46921 to 0.55050, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 6/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.6494 - categorical_crossentropy: 1.6494 - categorical_accuracy: 0.5981 - top_3_accuracy: 0.7927 - val_loss: 1.8021 - val_categorical_crossentropy: 1.8021 - val_categorical_accuracy: 0.5598 - val_top_3_accuracy: 0.7620\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.55050 to 0.55982, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 7/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.6533 - categorical_crossentropy: 1.6533 - categorical_accuracy: 0.5968 - top_3_accuracy: 0.7933 - val_loss: 2.7650 - val_categorical_crossentropy: 2.7650 - val_categorical_accuracy: 0.3891 - val_top_3_accuracy: 0.6197\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.55982\n",
      "Epoch 8/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.6448 - categorical_crossentropy: 1.6448 - categorical_accuracy: 0.5987 - top_3_accuracy: 0.7939 - val_loss: 2.2345 - val_categorical_crossentropy: 2.2345 - val_categorical_accuracy: 0.4649 - val_top_3_accuracy: 0.6785\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.55982\n",
      "Epoch 9/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.6817 - categorical_crossentropy: 1.6817 - categorical_accuracy: 0.5902 - top_3_accuracy: 0.7872 - val_loss: 1.7133 - val_categorical_crossentropy: 1.7133 - val_categorical_accuracy: 0.5778 - val_top_3_accuracy: 0.7775\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.55982 to 0.57779, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 10/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.5410 - categorical_crossentropy: 1.5410 - categorical_accuracy: 0.6216 - top_3_accuracy: 0.8105 - val_loss: 2.0105 - val_categorical_crossentropy: 2.0105 - val_categorical_accuracy: 0.5128 - val_top_3_accuracy: 0.7218\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.57779\n",
      "Epoch 11/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.4316 - categorical_crossentropy: 1.4316 - categorical_accuracy: 0.6464 - top_3_accuracy: 0.8293 - val_loss: 5.7516 - val_categorical_crossentropy: 5.7516 - val_categorical_accuracy: 0.1182 - val_top_3_accuracy: 0.2198\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.57779\n",
      "Epoch 12/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.6013 - categorical_crossentropy: 1.6013 - categorical_accuracy: 0.6092 - top_3_accuracy: 0.8018 - val_loss: 2.1606 - val_categorical_crossentropy: 2.1606 - val_categorical_accuracy: 0.4789 - val_top_3_accuracy: 0.6964\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.57779\n",
      "Epoch 13/50\n",
      "518/517 [==============================] - 156s 300ms/step - loss: 1.4746 - categorical_crossentropy: 1.4746 - categorical_accuracy: 0.6374 - top_3_accuracy: 0.8237 - val_loss: 1.4431 - val_categorical_crossentropy: 1.4431 - val_categorical_accuracy: 0.6431 - val_top_3_accuracy: 0.8275\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.57779 to 0.64309, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 14/50\n",
      "518/517 [==============================] - 156s 300ms/step - loss: 1.3904 - categorical_crossentropy: 1.3904 - categorical_accuracy: 0.6559 - top_3_accuracy: 0.8362 - val_loss: 1.8833 - val_categorical_crossentropy: 1.8833 - val_categorical_accuracy: 0.5626 - val_top_3_accuracy: 0.7760\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.64309\n",
      "Epoch 15/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.4276 - categorical_crossentropy: 1.4276 - categorical_accuracy: 0.6473 - top_3_accuracy: 0.8299 - val_loss: 3.2892 - val_categorical_crossentropy: 3.2892 - val_categorical_accuracy: 0.3266 - val_top_3_accuracy: 0.5254\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.64309\n",
      "Epoch 16/50\n",
      "518/517 [==============================] - 156s 300ms/step - loss: 1.3786 - categorical_crossentropy: 1.3786 - categorical_accuracy: 0.6591 - top_3_accuracy: 0.8381 - val_loss: 1.6662 - val_categorical_crossentropy: 1.6662 - val_categorical_accuracy: 0.5839 - val_top_3_accuracy: 0.7855\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.64309\n",
      "Epoch 17/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.5315 - categorical_crossentropy: 1.5315 - categorical_accuracy: 0.6251 - top_3_accuracy: 0.8124 - val_loss: 1.5411 - val_categorical_crossentropy: 1.5411 - val_categorical_accuracy: 0.6156 - val_top_3_accuracy: 0.8079\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy did not improve from 0.64309\n",
      "Epoch 18/50\n",
      "518/517 [==============================] - 156s 300ms/step - loss: 1.6100 - categorical_crossentropy: 1.6100 - categorical_accuracy: 0.6079 - top_3_accuracy: 0.7983 - val_loss: 1.4468 - val_categorical_crossentropy: 1.4468 - val_categorical_accuracy: 0.6401 - val_top_3_accuracy: 0.8256\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0010000000474974513.\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.64309\n",
      "Epoch 19/50\n",
      "518/517 [==============================] - 155s 300ms/step - loss: 1.3737 - categorical_crossentropy: 1.3737 - categorical_accuracy: 0.6605 - top_3_accuracy: 0.8372 - val_loss: 1.4735 - val_categorical_crossentropy: 1.4735 - val_categorical_accuracy: 0.6344 - val_top_3_accuracy: 0.8201\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.64309\n",
      "Epoch 20/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.3157 - categorical_crossentropy: 1.3157 - categorical_accuracy: 0.6743 - top_3_accuracy: 0.8478 - val_loss: 1.3951 - val_categorical_crossentropy: 1.3951 - val_categorical_accuracy: 0.6601 - val_top_3_accuracy: 0.8377\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy improved from 0.64309 to 0.66006, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 21/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.2794 - categorical_crossentropy: 1.2794 - categorical_accuracy: 0.6825 - top_3_accuracy: 0.8531 - val_loss: 1.2595 - val_categorical_crossentropy: 1.2595 - val_categorical_accuracy: 0.6850 - val_top_3_accuracy: 0.8540\n",
      "\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.66006 to 0.68503, saving model to ./models/inceptionv3_raw_head75.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50\n",
      "518/517 [==============================] - 156s 301ms/step - loss: 1.2895 - categorical_crossentropy: 1.2895 - categorical_accuracy: 0.6808 - top_3_accuracy: 0.8520 - val_loss: 1.3260 - val_categorical_crossentropy: 1.3260 - val_categorical_accuracy: 0.6686 - val_top_3_accuracy: 0.8440\n",
      "\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.68503\n",
      "Epoch 23/50\n",
      "518/517 [==============================] - 155s 300ms/step - loss: 1.2986 - categorical_crossentropy: 1.2986 - categorical_accuracy: 0.6787 - top_3_accuracy: 0.8504 - val_loss: 1.2835 - val_categorical_crossentropy: 1.2835 - val_categorical_accuracy: 0.6780 - val_top_3_accuracy: 0.8481\n",
      "\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.68503\n",
      "Epoch 24/50\n",
      "518/517 [==============================] - 154s 297ms/step - loss: 1.3095 - categorical_crossentropy: 1.3095 - categorical_accuracy: 0.6752 - top_3_accuracy: 0.8488 - val_loss: 1.3253 - val_categorical_crossentropy: 1.3253 - val_categorical_accuracy: 0.6745 - val_top_3_accuracy: 0.8471\n",
      "\n",
      "Epoch 00024: val_categorical_accuracy did not improve from 0.68503\n",
      "Epoch 25/50\n",
      "518/517 [==============================] - 153s 296ms/step - loss: 1.2615 - categorical_crossentropy: 1.2615 - categorical_accuracy: 0.6864 - top_3_accuracy: 0.8564 - val_loss: 1.2573 - val_categorical_crossentropy: 1.2573 - val_categorical_accuracy: 0.6906 - val_top_3_accuracy: 0.8557\n",
      "\n",
      "Epoch 00025: val_categorical_accuracy improved from 0.68503 to 0.69062, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 26/50\n",
      "518/517 [==============================] - 153s 294ms/step - loss: 1.3032 - categorical_crossentropy: 1.3032 - categorical_accuracy: 0.6770 - top_3_accuracy: 0.8494 - val_loss: 1.2378 - val_categorical_crossentropy: 1.2378 - val_categorical_accuracy: 0.6907 - val_top_3_accuracy: 0.8564\n",
      "\n",
      "Epoch 00026: val_categorical_accuracy improved from 0.69062 to 0.69068, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 27/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.2307 - categorical_crossentropy: 1.2307 - categorical_accuracy: 0.6939 - top_3_accuracy: 0.8609 - val_loss: 1.2545 - val_categorical_crossentropy: 1.2545 - val_categorical_accuracy: 0.6858 - val_top_3_accuracy: 0.8549\n",
      "\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.69068\n",
      "Epoch 28/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.2246 - categorical_crossentropy: 1.2246 - categorical_accuracy: 0.6955 - top_3_accuracy: 0.8627 - val_loss: 1.2185 - val_categorical_crossentropy: 1.2185 - val_categorical_accuracy: 0.6961 - val_top_3_accuracy: 0.8616\n",
      "\n",
      "Epoch 00028: val_categorical_accuracy improved from 0.69068 to 0.69606, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 29/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.1962 - categorical_crossentropy: 1.1962 - categorical_accuracy: 0.7022 - top_3_accuracy: 0.8666 - val_loss: 1.7643 - val_categorical_crossentropy: 1.7643 - val_categorical_accuracy: 0.5687 - val_top_3_accuracy: 0.7735\n",
      "\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.69606\n",
      "Epoch 30/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.2586 - categorical_crossentropy: 1.2586 - categorical_accuracy: 0.6864 - top_3_accuracy: 0.8570 - val_loss: 1.6710 - val_categorical_crossentropy: 1.6710 - val_categorical_accuracy: 0.5896 - val_top_3_accuracy: 0.7899\n",
      "\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.69606\n",
      "Epoch 31/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.2070 - categorical_crossentropy: 1.2070 - categorical_accuracy: 0.6990 - top_3_accuracy: 0.8652 - val_loss: 1.1959 - val_categorical_crossentropy: 1.1959 - val_categorical_accuracy: 0.6999 - val_top_3_accuracy: 0.8629\n",
      "\n",
      "Epoch 00031: val_categorical_accuracy improved from 0.69606 to 0.69988, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 32/50\n",
      "518/517 [==============================] - 153s 294ms/step - loss: 1.1605 - categorical_crossentropy: 1.1605 - categorical_accuracy: 0.7097 - top_3_accuracy: 0.8713 - val_loss: 1.1756 - val_categorical_crossentropy: 1.1756 - val_categorical_accuracy: 0.7075 - val_top_3_accuracy: 0.8684\n",
      "\n",
      "Epoch 00032: val_categorical_accuracy improved from 0.69988 to 0.70747, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 33/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.1505 - categorical_crossentropy: 1.1505 - categorical_accuracy: 0.7135 - top_3_accuracy: 0.8735 - val_loss: 1.1894 - val_categorical_crossentropy: 1.1894 - val_categorical_accuracy: 0.7003 - val_top_3_accuracy: 0.8638\n",
      "\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.70747\n",
      "Epoch 34/50\n",
      "518/517 [==============================] - 152s 294ms/step - loss: 1.1389 - categorical_crossentropy: 1.1389 - categorical_accuracy: 0.7150 - top_3_accuracy: 0.8749 - val_loss: 1.1489 - val_categorical_crossentropy: 1.1489 - val_categorical_accuracy: 0.7106 - val_top_3_accuracy: 0.8724\n",
      "\n",
      "Epoch 00034: val_categorical_accuracy improved from 0.70747 to 0.71065, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 35/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.1970 - categorical_crossentropy: 1.1970 - categorical_accuracy: 0.7012 - top_3_accuracy: 0.8663 - val_loss: 1.2055 - val_categorical_crossentropy: 1.2055 - val_categorical_accuracy: 0.6974 - val_top_3_accuracy: 0.8613\n",
      "\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.71065\n",
      "Epoch 36/50\n",
      "518/517 [==============================] - 152s 294ms/step - loss: 1.1678 - categorical_crossentropy: 1.1678 - categorical_accuracy: 0.7087 - top_3_accuracy: 0.8706 - val_loss: 1.3831 - val_categorical_crossentropy: 1.3831 - val_categorical_accuracy: 0.6599 - val_top_3_accuracy: 0.8419\n",
      "\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.71065\n",
      "Epoch 37/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.1468 - categorical_crossentropy: 1.1468 - categorical_accuracy: 0.7141 - top_3_accuracy: 0.8743 - val_loss: 1.1506 - val_categorical_crossentropy: 1.1506 - val_categorical_accuracy: 0.7104 - val_top_3_accuracy: 0.8699\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.71065\n",
      "Epoch 38/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.1355 - categorical_crossentropy: 1.1355 - categorical_accuracy: 0.7163 - top_3_accuracy: 0.8754 - val_loss: 1.1301 - val_categorical_crossentropy: 1.1301 - val_categorical_accuracy: 0.7173 - val_top_3_accuracy: 0.8739\n",
      "\n",
      "Epoch 00038: val_categorical_accuracy improved from 0.71065 to 0.71732, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 39/50\n",
      "518/517 [==============================] - 153s 294ms/step - loss: 1.1075 - categorical_crossentropy: 1.1075 - categorical_accuracy: 0.7235 - top_3_accuracy: 0.8792 - val_loss: 1.1106 - val_categorical_crossentropy: 1.1106 - val_categorical_accuracy: 0.7201 - val_top_3_accuracy: 0.8758\n",
      "\n",
      "Epoch 00039: val_categorical_accuracy improved from 0.71732 to 0.72015, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 40/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0978 - categorical_crossentropy: 1.0978 - categorical_accuracy: 0.7269 - top_3_accuracy: 0.8810 - val_loss: 1.1723 - val_categorical_crossentropy: 1.1723 - val_categorical_accuracy: 0.7131 - val_top_3_accuracy: 0.8699\n",
      "\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.72015\n",
      "Epoch 41/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0982 - categorical_crossentropy: 1.0982 - categorical_accuracy: 0.7259 - top_3_accuracy: 0.8806 - val_loss: 1.1096 - val_categorical_crossentropy: 1.1096 - val_categorical_accuracy: 0.7200 - val_top_3_accuracy: 0.8771\n",
      "\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.72015\n",
      "Epoch 42/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0842 - categorical_crossentropy: 1.0842 - categorical_accuracy: 0.7287 - top_3_accuracy: 0.8831 - val_loss: 1.0696 - val_categorical_crossentropy: 1.0696 - val_categorical_accuracy: 0.7327 - val_top_3_accuracy: 0.8820\n",
      "\n",
      "Epoch 00042: val_categorical_accuracy improved from 0.72015 to 0.73274, saving model to ./models/inceptionv3_raw_head75.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50\n",
      "518/517 [==============================] - 153s 294ms/step - loss: 1.0851 - categorical_crossentropy: 1.0851 - categorical_accuracy: 0.7291 - top_3_accuracy: 0.8830 - val_loss: 1.0769 - val_categorical_crossentropy: 1.0769 - val_categorical_accuracy: 0.7326 - val_top_3_accuracy: 0.8819\n",
      "\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.73274\n",
      "Epoch 44/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0900 - categorical_crossentropy: 1.0900 - categorical_accuracy: 0.7276 - top_3_accuracy: 0.8818 - val_loss: 1.0821 - val_categorical_crossentropy: 1.0821 - val_categorical_accuracy: 0.7296 - val_top_3_accuracy: 0.8801\n",
      "\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.73274\n",
      "Epoch 45/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0726 - categorical_crossentropy: 1.0726 - categorical_accuracy: 0.7319 - top_3_accuracy: 0.8845 - val_loss: 1.2518 - val_categorical_crossentropy: 1.2518 - val_categorical_accuracy: 0.6826 - val_top_3_accuracy: 0.8524\n",
      "\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.73274\n",
      "Epoch 46/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.1603 - categorical_crossentropy: 1.1603 - categorical_accuracy: 0.7187 - top_3_accuracy: 0.8768 - val_loss: 1.2426 - val_categorical_crossentropy: 1.2426 - val_categorical_accuracy: 0.6946 - val_top_3_accuracy: 0.8634\n",
      "\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.73274\n",
      "Epoch 47/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0794 - categorical_crossentropy: 1.0794 - categorical_accuracy: 0.7295 - top_3_accuracy: 0.8842 - val_loss: 1.0709 - val_categorical_crossentropy: 1.0709 - val_categorical_accuracy: 0.7289 - val_top_3_accuracy: 0.8832\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.73274\n",
      "Epoch 48/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0698 - categorical_crossentropy: 1.0698 - categorical_accuracy: 0.7330 - top_3_accuracy: 0.8844 - val_loss: 1.0760 - val_categorical_crossentropy: 1.0760 - val_categorical_accuracy: 0.7344 - val_top_3_accuracy: 0.8839\n",
      "\n",
      "Epoch 00048: val_categorical_accuracy improved from 0.73274 to 0.73444, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 49/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0673 - categorical_crossentropy: 1.0673 - categorical_accuracy: 0.7343 - top_3_accuracy: 0.8845 - val_loss: 1.0550 - val_categorical_crossentropy: 1.0550 - val_categorical_accuracy: 0.7350 - val_top_3_accuracy: 0.8847\n",
      "\n",
      "Epoch 00049: val_categorical_accuracy improved from 0.73444 to 0.73497, saving model to ./models/inceptionv3_raw_head75.model\n",
      "Epoch 50/50\n",
      "518/517 [==============================] - 153s 295ms/step - loss: 1.0543 - categorical_crossentropy: 1.0543 - categorical_accuracy: 0.7371 - top_3_accuracy: 0.8861 - val_loss: 1.0464 - val_categorical_crossentropy: 1.0464 - val_categorical_accuracy: 0.7355 - val_top_3_accuracy: 0.8868\n",
      "\n",
      "Epoch 00050: val_categorical_accuracy improved from 0.73497 to 0.73550, saving model to ./models/inceptionv3_raw_head75.model\n"
     ]
    }
   ],
   "source": [
    "hists = []\n",
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}{}.model'.format(model_prefix, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112199, 3) (112199, 75, 75, 1)\n",
      "Test array memory 2.35 GB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../input/test_simplified.csv')\n",
    "test.head()\n",
    "x_test = df_to_image_array_xd(test, size, lw=lw, \n",
    "                              preprocess_input=preprocess_input,\n",
    "                             channel=channel)\n",
    "print(test.shape, x_test.shape)\n",
    "print('Test array memory {:.2f} GB'.format(x_test.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112199/112199 [==============================] - 25s 221us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(112199, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(x_test, batch_size=128, verbose=1)\n",
    "\n",
    "top3 = preds2catids(test_predictions)\n",
    "top3.head()\n",
    "top3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112199, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_classes = np.load('../input/classes.npy')\n",
    "id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(np_classes)}\n",
    "top3cats = top3.replace(id2cat)\n",
    "top3cats.head()\n",
    "top3cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_id</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9000003627287624</td>\n",
       "      <td>radio stereo alarm_clock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9000010688666847</td>\n",
       "      <td>hockey_puck steak pool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000023642890129</td>\n",
       "      <td>The_Great_Wall_of_China castle fence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9000038588854897</td>\n",
       "      <td>mountain tent The_Eiffel_Tower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9000052667981386</td>\n",
       "      <td>fireplace campfire crown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             key_id                                  word\n",
       "0  9000003627287624              radio stereo alarm_clock\n",
       "1  9000010688666847                hockey_puck steak pool\n",
       "2  9000023642890129  The_Great_Wall_of_China castle fence\n",
       "3  9000038588854897        mountain tent The_Eiffel_Tower\n",
       "4  9000052667981386              fireplace campfire crown"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\n",
    "submission = test[['key_id', 'word']]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save result\n",
      "upload result\n",
      "cmd: kaggle competitions submit -c quickdraw-doodle-recognition -f ../result/inceptionv3_raw_head75.csv.7z -m \"submit\"\n"
     ]
    }
   ],
   "source": [
    "import kaggle_util\n",
    "kaggle_util.save_result(submission, \n",
    "                        '../result/{}{}.csv'.format(model_prefix, size), \n",
    "                        'quickdraw-doodle-recognition', \n",
    "                        send=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
