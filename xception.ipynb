{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "import ast\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras.legacy import interfaces\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from data import *\n",
    "from keras_helper import *\n",
    "\n",
    "from keras.applications import Xception\n",
    "from keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT = 49673580\n",
    "EPOCHS = 50 * 3\n",
    "size = 128\n",
    "batchsize = 64\n",
    "lw = 6\n",
    "STEPS = TOT / EPOCHS / batchsize\n",
    "NCATS = 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   288         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 61, 61, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 61, 61, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 61, 61, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 61, 61, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 31, 31, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 31, 31, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 31, 31, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 31, 31, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 31, 31, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 31, 31, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 31, 31, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 31, 31, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 16, 16, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 16, 16, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 16, 16, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 16, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 16, 16, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 16, 16, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 16, 16, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 8, 8, 728)    186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 8, 8, 728)    0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 8, 8, 728)    2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 8, 728)    0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 8, 8, 728)    0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 8, 8, 728)    0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 8, 8, 728)    0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 8, 8, 728)    0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 8, 8, 728)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 8, 8, 728)    0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 8, 8, 728)    0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 8, 8, 728)    0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 8, 8, 728)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 8, 8, 728)    0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 8, 8, 728)    0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 8, 8, 728)    0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 8, 8, 728)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 8, 8, 728)    0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 8, 8, 728)    0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 8, 8, 728)    0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 8, 8, 728)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 8, 8, 728)    0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 8, 8, 728)    0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 8, 8, 728)    536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 8, 8, 728)    2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 8, 8, 728)    0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 8, 8, 728)    0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 8, 8, 728)    0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 8, 8, 728)    0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 8, 8, 728)    0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 8, 8, 728)    0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 8, 8, 728)    0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 8, 8, 728)    0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 8, 8, 728)    0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 8, 8, 728)    536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 8, 8, 728)    2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 8, 8, 728)    0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 8, 8, 728)    0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 8, 8, 728)    536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 8, 8, 728)    2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 8, 8, 728)    0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 8, 8, 1024)   752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 8, 8, 1024)   4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 4, 4, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 4, 4, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4, 4, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 4, 4, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 4, 4, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 4, 4, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 4, 4, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 4, 4, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 4, 4, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 4, 4, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 340)          696660      avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 21,557,564\n",
      "Trainable params: 21,503,036\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "model = Xception(input_shape=(size, size, 1), weights=None, classes=NCATS)\n",
    "model.compile(optimizer=Adam(lr=0.02), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('../input/valid.csv')\n",
    "x_valid = df_to_image_array_xd(valid_df, size, lw = lw, preprocess_input=preprocess_input)\n",
    "y_valid = keras.utils.to_categorical(valid_df.word, num_classes=NCATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34000, 128, 128, 1) (34000, 340)\n",
      "Validation array memory 2.08 GB\n"
     ]
    }
   ],
   "source": [
    "print(x_valid.shape, y_valid.shape)\n",
    "print('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image_generator_xd(size=size, \n",
    "                                   batchsize=batchsize, \n",
    "                                   lw = lw,\n",
    "                                   preprocess_input=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5175/5174 [==============================] - 1268s 245ms/step - loss: 1.4905 - categorical_crossentropy: 1.4905 - categorical_accuracy: 0.6555 - top_3_accuracy: 0.8185 - val_loss: 1.5228 - val_categorical_crossentropy: 1.5228 - val_categorical_accuracy: 0.6467 - val_top_3_accuracy: 0.8102\n",
      "\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.64674, saving model to ./models/xception128_lw6.model\n",
      "Epoch 2/150\n",
      "5175/5174 [==============================] - 1262s 244ms/step - loss: 1.4871 - categorical_crossentropy: 1.4871 - categorical_accuracy: 0.6563 - top_3_accuracy: 0.8191 - val_loss: 1.4600 - val_categorical_crossentropy: 1.4600 - val_categorical_accuracy: 0.6671 - val_top_3_accuracy: 0.8267\n",
      "\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.64674 to 0.66709, saving model to ./models/xception128_lw6.model\n",
      "Epoch 3/150\n",
      "5175/5174 [==============================] - 1260s 244ms/step - loss: 1.4660 - categorical_crossentropy: 1.4660 - categorical_accuracy: 0.6594 - top_3_accuracy: 0.8230 - val_loss: 1.4550 - val_categorical_crossentropy: 1.4550 - val_categorical_accuracy: 0.6639 - val_top_3_accuracy: 0.8239\n",
      "\n",
      "Epoch 00003: val_categorical_accuracy did not improve from 0.66709\n",
      "Epoch 4/150\n",
      "5175/5174 [==============================] - 1261s 244ms/step - loss: 1.4586 - categorical_crossentropy: 1.4586 - categorical_accuracy: 0.6628 - top_3_accuracy: 0.8241 - val_loss: 1.4363 - val_categorical_crossentropy: 1.4363 - val_categorical_accuracy: 0.6692 - val_top_3_accuracy: 0.8273\n",
      "\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.66709 to 0.66921, saving model to ./models/xception128_lw6.model\n",
      "Epoch 5/150\n",
      "5175/5174 [==============================] - 1261s 244ms/step - loss: 1.4391 - categorical_crossentropy: 1.4391 - categorical_accuracy: 0.6674 - top_3_accuracy: 0.8272 - val_loss: 1.4211 - val_categorical_crossentropy: 1.4211 - val_categorical_accuracy: 0.6726 - val_top_3_accuracy: 0.8271\n",
      "\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.66921 to 0.67265, saving model to ./models/xception128_lw6.model\n",
      "Epoch 6/150\n",
      "5175/5174 [==============================] - 1261s 244ms/step - loss: 1.4221 - categorical_crossentropy: 1.4221 - categorical_accuracy: 0.6718 - top_3_accuracy: 0.8299 - val_loss: 1.4410 - val_categorical_crossentropy: 1.4410 - val_categorical_accuracy: 0.6649 - val_top_3_accuracy: 0.8256\n",
      "\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.67265\n",
      "Epoch 7/150\n",
      "5175/5174 [==============================] - 1261s 244ms/step - loss: 1.4134 - categorical_crossentropy: 1.4134 - categorical_accuracy: 0.6730 - top_3_accuracy: 0.8308 - val_loss: 1.4025 - val_categorical_crossentropy: 1.4025 - val_categorical_accuracy: 0.6815 - val_top_3_accuracy: 0.8354\n",
      "\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.67265 to 0.68147, saving model to ./models/xception128_lw6.model\n",
      "Epoch 8/150\n",
      "5175/5174 [==============================] - 1262s 244ms/step - loss: 1.3988 - categorical_crossentropy: 1.3988 - categorical_accuracy: 0.6757 - top_3_accuracy: 0.8327 - val_loss: 1.3750 - val_categorical_crossentropy: 1.3750 - val_categorical_accuracy: 0.6850 - val_top_3_accuracy: 0.8363\n",
      "\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.68147 to 0.68500, saving model to ./models/xception128_lw6.model\n",
      "Epoch 9/150\n",
      "5175/5174 [==============================] - 1261s 244ms/step - loss: 1.3930 - categorical_crossentropy: 1.3930 - categorical_accuracy: 0.6782 - top_3_accuracy: 0.8339 - val_loss: 1.3701 - val_categorical_crossentropy: 1.3701 - val_categorical_accuracy: 0.6851 - val_top_3_accuracy: 0.8387\n",
      "\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.68500 to 0.68515, saving model to ./models/xception128_lw6.model\n",
      "Epoch 10/150\n",
      "5175/5174 [==============================] - 1262s 244ms/step - loss: 1.3736 - categorical_crossentropy: 1.3736 - categorical_accuracy: 0.6825 - top_3_accuracy: 0.8366 - val_loss: 1.3736 - val_categorical_crossentropy: 1.3736 - val_categorical_accuracy: 0.6830 - val_top_3_accuracy: 0.8359\n",
      "\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.68515\n",
      "Epoch 11/150\n",
      "5175/5174 [==============================] - 1261s 244ms/step - loss: 1.3565 - categorical_crossentropy: 1.3565 - categorical_accuracy: 0.6855 - top_3_accuracy: 0.8391 - val_loss: 1.3724 - val_categorical_crossentropy: 1.3724 - val_categorical_accuracy: 0.6837 - val_top_3_accuracy: 0.8370\n",
      "\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.68515\n",
      "Epoch 12/150\n",
      "5175/5174 [==============================] - 1262s 244ms/step - loss: 1.3541 - categorical_crossentropy: 1.3541 - categorical_accuracy: 0.6863 - top_3_accuracy: 0.8395 - val_loss: 1.3722 - val_categorical_crossentropy: 1.3722 - val_categorical_accuracy: 0.6886 - val_top_3_accuracy: 0.8388\n",
      "\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.68515 to 0.68856, saving model to ./models/xception128_lw6.model\n",
      "Epoch 13/150\n",
      "5175/5174 [==============================] - 1262s 244ms/step - loss: 1.3424 - categorical_crossentropy: 1.3424 - categorical_accuracy: 0.6888 - top_3_accuracy: 0.8418 - val_loss: 1.3386 - val_categorical_crossentropy: 1.3386 - val_categorical_accuracy: 0.6893 - val_top_3_accuracy: 0.8417\n",
      "\n",
      "Epoch 00013: val_categorical_accuracy improved from 0.68856 to 0.68929, saving model to ./models/xception128_lw6.model\n",
      "Epoch 14/150\n",
      "5175/5174 [==============================] - 1262s 244ms/step - loss: 1.3403 - categorical_crossentropy: 1.3403 - categorical_accuracy: 0.6901 - top_3_accuracy: 0.8419 - val_loss: 1.3552 - val_categorical_crossentropy: 1.3552 - val_categorical_accuracy: 0.6874 - val_top_3_accuracy: 0.8386\n",
      "\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.68929\n",
      "Epoch 15/150\n",
      "5175/5174 [==============================] - 1263s 244ms/step - loss: 1.3325 - categorical_crossentropy: 1.3325 - categorical_accuracy: 0.6913 - top_3_accuracy: 0.8433 - val_loss: 1.3220 - val_categorical_crossentropy: 1.3220 - val_categorical_accuracy: 0.6998 - val_top_3_accuracy: 0.8451\n",
      "\n",
      "Epoch 00015: val_categorical_accuracy improved from 0.68929 to 0.69982, saving model to ./models/xception128_lw6.model\n",
      "Epoch 16/150\n",
      "5175/5174 [==============================] - 1263s 244ms/step - loss: 1.3259 - categorical_crossentropy: 1.3259 - categorical_accuracy: 0.6936 - top_3_accuracy: 0.8441 - val_loss: 1.2953 - val_categorical_crossentropy: 1.2953 - val_categorical_accuracy: 0.7035 - val_top_3_accuracy: 0.8488\n",
      "\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.69982 to 0.70347, saving model to ./models/xception128_lw6.model\n",
      "Epoch 17/150\n",
      "5175/5174 [==============================] - 1263s 244ms/step - loss: 1.3102 - categorical_crossentropy: 1.3102 - categorical_accuracy: 0.6957 - top_3_accuracy: 0.8470 - val_loss: 1.2797 - val_categorical_crossentropy: 1.2797 - val_categorical_accuracy: 0.7036 - val_top_3_accuracy: 0.8510\n",
      "\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.70347 to 0.70359, saving model to ./models/xception128_lw6.model\n",
      "Epoch 18/150\n",
      "5175/5174 [==============================] - 1263s 244ms/step - loss: 1.2978 - categorical_crossentropy: 1.2978 - categorical_accuracy: 0.6997 - top_3_accuracy: 0.8476 - val_loss: 1.2855 - val_categorical_crossentropy: 1.2855 - val_categorical_accuracy: 0.7040 - val_top_3_accuracy: 0.8486\n",
      "\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.70359 to 0.70403, saving model to ./models/xception128_lw6.model\n",
      "Epoch 19/150\n",
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.3093 - categorical_crossentropy: 1.3093 - categorical_accuracy: 0.6969 - top_3_accuracy: 0.8461 - val_loss: 1.3345 - val_categorical_crossentropy: 1.3345 - val_categorical_accuracy: 0.6923 - val_top_3_accuracy: 0.8426\n",
      "\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.70403\n",
      "Epoch 20/150\n",
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.3015 - categorical_crossentropy: 1.3015 - categorical_accuracy: 0.6987 - top_3_accuracy: 0.8479 - val_loss: 1.2895 - val_categorical_crossentropy: 1.2895 - val_categorical_accuracy: 0.7036 - val_top_3_accuracy: 0.8492\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.009999999776482582.\n",
      "\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.70403\n",
      "Epoch 21/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.2267 - categorical_crossentropy: 1.2267 - categorical_accuracy: 0.7164 - top_3_accuracy: 0.8589 - val_loss: 1.1997 - val_categorical_crossentropy: 1.1997 - val_categorical_accuracy: 0.7231 - val_top_3_accuracy: 0.8602\n",
      "\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.70403 to 0.72306, saving model to ./models/xception128_lw6.model\n",
      "Epoch 22/150\n",
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.2123 - categorical_crossentropy: 1.2123 - categorical_accuracy: 0.7209 - top_3_accuracy: 0.8609 - val_loss: 1.1857 - val_categorical_crossentropy: 1.1857 - val_categorical_accuracy: 0.7280 - val_top_3_accuracy: 0.8641\n",
      "\n",
      "Epoch 00022: val_categorical_accuracy improved from 0.72306 to 0.72803, saving model to ./models/xception128_lw6.model\n",
      "Epoch 23/150\n",
      "5175/5174 [==============================] - 1260s 244ms/step - loss: 1.2112 - categorical_crossentropy: 1.2112 - categorical_accuracy: 0.7197 - top_3_accuracy: 0.8605 - val_loss: 1.1660 - val_categorical_crossentropy: 1.1660 - val_categorical_accuracy: 0.7320 - val_top_3_accuracy: 0.8684\n",
      "\n",
      "Epoch 00023: val_categorical_accuracy improved from 0.72803 to 0.73203, saving model to ./models/xception128_lw6.model\n",
      "Epoch 24/150\n",
      "5175/5174 [==============================] - 1267s 245ms/step - loss: 1.2003 - categorical_crossentropy: 1.2003 - categorical_accuracy: 0.7226 - top_3_accuracy: 0.8625 - val_loss: 1.1582 - val_categorical_crossentropy: 1.1582 - val_categorical_accuracy: 0.7335 - val_top_3_accuracy: 0.8691\n",
      "\n",
      "Epoch 00024: val_categorical_accuracy improved from 0.73203 to 0.73350, saving model to ./models/xception128_lw6.model\n",
      "Epoch 25/150\n",
      "5175/5174 [==============================] - 1269s 245ms/step - loss: 1.1951 - categorical_crossentropy: 1.1951 - categorical_accuracy: 0.7224 - top_3_accuracy: 0.8640 - val_loss: 1.1681 - val_categorical_crossentropy: 1.1681 - val_categorical_accuracy: 0.7304 - val_top_3_accuracy: 0.8667\n",
      "\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.73350\n",
      "Epoch 26/150\n",
      "5175/5174 [==============================] - 1270s 245ms/step - loss: 1.1892 - categorical_crossentropy: 1.1892 - categorical_accuracy: 0.7248 - top_3_accuracy: 0.8643 - val_loss: 1.1506 - val_categorical_crossentropy: 1.1506 - val_categorical_accuracy: 0.7359 - val_top_3_accuracy: 0.8711\n",
      "\n",
      "Epoch 00026: val_categorical_accuracy improved from 0.73350 to 0.73588, saving model to ./models/xception128_lw6.model\n",
      "Epoch 27/150\n",
      "5175/5174 [==============================] - 1270s 245ms/step - loss: 1.1845 - categorical_crossentropy: 1.1845 - categorical_accuracy: 0.7266 - top_3_accuracy: 0.8652 - val_loss: 1.1657 - val_categorical_crossentropy: 1.1657 - val_categorical_accuracy: 0.7352 - val_top_3_accuracy: 0.8658\n",
      "\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.73588\n",
      "Epoch 28/150\n",
      "5175/5174 [==============================] - 1269s 245ms/step - loss: 1.1807 - categorical_crossentropy: 1.1807 - categorical_accuracy: 0.7273 - top_3_accuracy: 0.8661 - val_loss: 1.1534 - val_categorical_crossentropy: 1.1534 - val_categorical_accuracy: 0.7366 - val_top_3_accuracy: 0.8694\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\n",
      "Epoch 00028: val_categorical_accuracy improved from 0.73588 to 0.73659, saving model to ./models/xception128_lw6.model\n",
      "Epoch 29/150\n",
      "5175/5174 [==============================] - 1268s 245ms/step - loss: 1.1508 - categorical_crossentropy: 1.1508 - categorical_accuracy: 0.7352 - top_3_accuracy: 0.8702 - val_loss: 1.1122 - val_categorical_crossentropy: 1.1122 - val_categorical_accuracy: 0.7432 - val_top_3_accuracy: 0.8742\n",
      "\n",
      "Epoch 00029: val_categorical_accuracy improved from 0.73659 to 0.74324, saving model to ./models/xception128_lw6.model\n",
      "Epoch 30/150\n",
      "5175/5174 [==============================] - 1268s 245ms/step - loss: 1.1434 - categorical_crossentropy: 1.1434 - categorical_accuracy: 0.7362 - top_3_accuracy: 0.8717 - val_loss: 1.1011 - val_categorical_crossentropy: 1.1011 - val_categorical_accuracy: 0.7464 - val_top_3_accuracy: 0.8764\n",
      "\n",
      "Epoch 00030: val_categorical_accuracy improved from 0.74324 to 0.74638, saving model to ./models/xception128_lw6.model\n",
      "Epoch 31/150\n",
      "5175/5174 [==============================] - 1268s 245ms/step - loss: 1.1337 - categorical_crossentropy: 1.1337 - categorical_accuracy: 0.7375 - top_3_accuracy: 0.8724 - val_loss: 1.1015 - val_categorical_crossentropy: 1.1015 - val_categorical_accuracy: 0.7467 - val_top_3_accuracy: 0.8776\n",
      "\n",
      "Epoch 00031: val_categorical_accuracy improved from 0.74638 to 0.74668, saving model to ./models/xception128_lw6.model\n",
      "Epoch 32/150\n",
      "5175/5174 [==============================] - 1267s 245ms/step - loss: 1.1250 - categorical_crossentropy: 1.1250 - categorical_accuracy: 0.7401 - top_3_accuracy: 0.8740 - val_loss: 1.0899 - val_categorical_crossentropy: 1.0899 - val_categorical_accuracy: 0.7501 - val_top_3_accuracy: 0.8798\n",
      "\n",
      "Epoch 00032: val_categorical_accuracy improved from 0.74668 to 0.75015, saving model to ./models/xception128_lw6.model\n",
      "Epoch 33/150\n",
      "5175/5174 [==============================] - 1267s 245ms/step - loss: 1.1224 - categorical_crossentropy: 1.1224 - categorical_accuracy: 0.7400 - top_3_accuracy: 0.8742 - val_loss: 1.0911 - val_categorical_crossentropy: 1.0911 - val_categorical_accuracy: 0.7493 - val_top_3_accuracy: 0.8771\n",
      "\n",
      "Epoch 00033: val_categorical_accuracy did not improve from 0.75015\n",
      "Epoch 34/150\n",
      "5175/5174 [==============================] - 1267s 245ms/step - loss: 1.1209 - categorical_crossentropy: 1.1209 - categorical_accuracy: 0.7403 - top_3_accuracy: 0.8748 - val_loss: 1.0895 - val_categorical_crossentropy: 1.0895 - val_categorical_accuracy: 0.7506 - val_top_3_accuracy: 0.8781\n",
      "\n",
      "Epoch 00034: val_categorical_accuracy improved from 0.75015 to 0.75065, saving model to ./models/xception128_lw6.model\n",
      "Epoch 35/150\n",
      "5175/5174 [==============================] - 1267s 245ms/step - loss: 1.1148 - categorical_crossentropy: 1.1148 - categorical_accuracy: 0.7419 - top_3_accuracy: 0.8752 - val_loss: 1.0842 - val_categorical_crossentropy: 1.0842 - val_categorical_accuracy: 0.7497 - val_top_3_accuracy: 0.8786\n",
      "\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.75065\n",
      "Epoch 36/150\n",
      "5175/5174 [==============================] - 1266s 245ms/step - loss: 1.1232 - categorical_crossentropy: 1.1232 - categorical_accuracy: 0.7400 - top_3_accuracy: 0.8735 - val_loss: 1.0784 - val_categorical_crossentropy: 1.0784 - val_categorical_accuracy: 0.7515 - val_top_3_accuracy: 0.8797\n",
      "\n",
      "Epoch 00036: val_categorical_accuracy improved from 0.75065 to 0.75153, saving model to ./models/xception128_lw6.model\n",
      "Epoch 37/150\n",
      "5175/5174 [==============================] - 1265s 245ms/step - loss: 1.1160 - categorical_crossentropy: 1.1160 - categorical_accuracy: 0.7426 - top_3_accuracy: 0.8751 - val_loss: 1.0868 - val_categorical_crossentropy: 1.0868 - val_categorical_accuracy: 0.7496 - val_top_3_accuracy: 0.8794\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.75153\n",
      "Epoch 38/150\n",
      "5175/5174 [==============================] - 1265s 245ms/step - loss: 1.0964 - categorical_crossentropy: 1.0964 - categorical_accuracy: 0.7474 - top_3_accuracy: 0.8777 - val_loss: 1.0608 - val_categorical_crossentropy: 1.0608 - val_categorical_accuracy: 0.7559 - val_top_3_accuracy: 0.8820\n",
      "\n",
      "Epoch 00038: val_categorical_accuracy improved from 0.75153 to 0.75591, saving model to ./models/xception128_lw6.model\n",
      "Epoch 39/150\n",
      "5175/5174 [==============================] - 1266s 245ms/step - loss: 1.0931 - categorical_crossentropy: 1.0931 - categorical_accuracy: 0.7478 - top_3_accuracy: 0.8784 - val_loss: 1.0635 - val_categorical_crossentropy: 1.0635 - val_categorical_accuracy: 0.7561 - val_top_3_accuracy: 0.8811\n",
      "\n",
      "Epoch 00039: val_categorical_accuracy improved from 0.75591 to 0.75612, saving model to ./models/xception128_lw6.model\n",
      "Epoch 40/150\n",
      "5175/5174 [==============================] - 1265s 245ms/step - loss: 1.0931 - categorical_crossentropy: 1.0931 - categorical_accuracy: 0.7477 - top_3_accuracy: 0.8779 - val_loss: 1.0624 - val_categorical_crossentropy: 1.0624 - val_categorical_accuracy: 0.7557 - val_top_3_accuracy: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.75612\n",
      "Epoch 41/150\n",
      "5175/5174 [==============================] - 1265s 245ms/step - loss: 1.0895 - categorical_crossentropy: 1.0895 - categorical_accuracy: 0.7482 - top_3_accuracy: 0.8787 - val_loss: 1.0581 - val_categorical_crossentropy: 1.0581 - val_categorical_accuracy: 0.7558 - val_top_3_accuracy: 0.8829\n",
      "\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.75612\n",
      "Epoch 42/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0855 - categorical_crossentropy: 1.0855 - categorical_accuracy: 0.7487 - top_3_accuracy: 0.8796 - val_loss: 1.0505 - val_categorical_crossentropy: 1.0505 - val_categorical_accuracy: 0.7579 - val_top_3_accuracy: 0.8844\n",
      "\n",
      "Epoch 00042: val_categorical_accuracy improved from 0.75612 to 0.75791, saving model to ./models/xception128_lw6.model\n",
      "Epoch 43/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0907 - categorical_crossentropy: 1.0907 - categorical_accuracy: 0.7478 - top_3_accuracy: 0.8789 - val_loss: 1.0535 - val_categorical_crossentropy: 1.0535 - val_categorical_accuracy: 0.7597 - val_top_3_accuracy: 0.8832\n",
      "\n",
      "Epoch 00043: val_categorical_accuracy improved from 0.75791 to 0.75968, saving model to ./models/xception128_lw6.model\n",
      "Epoch 44/150\n",
      "5175/5174 [==============================] - 1266s 245ms/step - loss: 1.0832 - categorical_crossentropy: 1.0832 - categorical_accuracy: 0.7498 - top_3_accuracy: 0.8794 - val_loss: 1.0522 - val_categorical_crossentropy: 1.0522 - val_categorical_accuracy: 0.7579 - val_top_3_accuracy: 0.8835\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.75968\n",
      "Epoch 45/150\n",
      "5175/5174 [==============================] - 1265s 245ms/step - loss: 1.0719 - categorical_crossentropy: 1.0719 - categorical_accuracy: 0.7524 - top_3_accuracy: 0.8805 - val_loss: 1.0429 - val_categorical_crossentropy: 1.0429 - val_categorical_accuracy: 0.7611 - val_top_3_accuracy: 0.8849\n",
      "\n",
      "Epoch 00045: val_categorical_accuracy improved from 0.75968 to 0.76109, saving model to ./models/xception128_lw6.model\n",
      "Epoch 46/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0699 - categorical_crossentropy: 1.0699 - categorical_accuracy: 0.7525 - top_3_accuracy: 0.8813 - val_loss: 1.0408 - val_categorical_crossentropy: 1.0408 - val_categorical_accuracy: 0.7592 - val_top_3_accuracy: 0.8844\n",
      "\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.76109\n",
      "Epoch 47/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0736 - categorical_crossentropy: 1.0736 - categorical_accuracy: 0.7517 - top_3_accuracy: 0.8811 - val_loss: 1.0400 - val_categorical_crossentropy: 1.0400 - val_categorical_accuracy: 0.7610 - val_top_3_accuracy: 0.8849\n",
      "\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.76109\n",
      "Epoch 48/150\n",
      "5175/5174 [==============================] - 1266s 245ms/step - loss: 1.0748 - categorical_crossentropy: 1.0748 - categorical_accuracy: 0.7527 - top_3_accuracy: 0.8813 - val_loss: 1.0389 - val_categorical_crossentropy: 1.0389 - val_categorical_accuracy: 0.7606 - val_top_3_accuracy: 0.8849\n",
      "\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.76109\n",
      "Epoch 49/150\n",
      "5175/5174 [==============================] - 1265s 245ms/step - loss: 1.0713 - categorical_crossentropy: 1.0713 - categorical_accuracy: 0.7528 - top_3_accuracy: 0.8811 - val_loss: 1.0391 - val_categorical_crossentropy: 1.0391 - val_categorical_accuracy: 0.7617 - val_top_3_accuracy: 0.8846\n",
      "\n",
      "Epoch 00049: val_categorical_accuracy improved from 0.76109 to 0.76171, saving model to ./models/xception128_lw6.model\n",
      "Epoch 50/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0704 - categorical_crossentropy: 1.0704 - categorical_accuracy: 0.7527 - top_3_accuracy: 0.8816 - val_loss: 1.0380 - val_categorical_crossentropy: 1.0380 - val_categorical_accuracy: 0.7611 - val_top_3_accuracy: 0.8855\n",
      "\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.76171\n",
      "Epoch 51/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0674 - categorical_crossentropy: 1.0674 - categorical_accuracy: 0.7542 - top_3_accuracy: 0.8818 - val_loss: 1.0358 - val_categorical_crossentropy: 1.0358 - val_categorical_accuracy: 0.7623 - val_top_3_accuracy: 0.8851\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\n",
      "Epoch 00051: val_categorical_accuracy improved from 0.76171 to 0.76229, saving model to ./models/xception128_lw6.model\n",
      "Epoch 52/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0642 - categorical_crossentropy: 1.0642 - categorical_accuracy: 0.7534 - top_3_accuracy: 0.8827 - val_loss: 1.0316 - val_categorical_crossentropy: 1.0316 - val_categorical_accuracy: 0.7628 - val_top_3_accuracy: 0.8854\n",
      "\n",
      "Epoch 00052: val_categorical_accuracy improved from 0.76229 to 0.76279, saving model to ./models/xception128_lw6.model\n",
      "Epoch 53/150\n",
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.0606 - categorical_crossentropy: 1.0606 - categorical_accuracy: 0.7550 - top_3_accuracy: 0.8828 - val_loss: 1.0323 - val_categorical_crossentropy: 1.0323 - val_categorical_accuracy: 0.7628 - val_top_3_accuracy: 0.8859\n",
      "\n",
      "Epoch 00053: val_categorical_accuracy improved from 0.76279 to 0.76282, saving model to ./models/xception128_lw6.model\n",
      "Epoch 54/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0583 - categorical_crossentropy: 1.0583 - categorical_accuracy: 0.7529 - top_3_accuracy: 0.8833 - val_loss: 1.0305 - val_categorical_crossentropy: 1.0305 - val_categorical_accuracy: 0.7639 - val_top_3_accuracy: 0.8864\n",
      "\n",
      "Epoch 00054: val_categorical_accuracy improved from 0.76282 to 0.76391, saving model to ./models/xception128_lw6.model\n",
      "Epoch 55/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0659 - categorical_crossentropy: 1.0659 - categorical_accuracy: 0.7550 - top_3_accuracy: 0.8823 - val_loss: 1.0304 - val_categorical_crossentropy: 1.0304 - val_categorical_accuracy: 0.7644 - val_top_3_accuracy: 0.8869\n",
      "\n",
      "Epoch 00055: val_categorical_accuracy improved from 0.76391 to 0.76441, saving model to ./models/xception128_lw6.model\n",
      "Epoch 56/150\n",
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.0651 - categorical_crossentropy: 1.0651 - categorical_accuracy: 0.7541 - top_3_accuracy: 0.8827 - val_loss: 1.0301 - val_categorical_crossentropy: 1.0301 - val_categorical_accuracy: 0.7633 - val_top_3_accuracy: 0.8866\n",
      "\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.76441\n",
      "Epoch 57/150\n",
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.0631 - categorical_crossentropy: 1.0631 - categorical_accuracy: 0.7540 - top_3_accuracy: 0.8829 - val_loss: 1.0298 - val_categorical_crossentropy: 1.0298 - val_categorical_accuracy: 0.7634 - val_top_3_accuracy: 0.8867\n",
      "\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.76441\n",
      "Epoch 58/150\n",
      "5175/5174 [==============================] - 1265s 244ms/step - loss: 1.0666 - categorical_crossentropy: 1.0666 - categorical_accuracy: 0.7541 - top_3_accuracy: 0.8821 - val_loss: 1.0302 - val_categorical_crossentropy: 1.0302 - val_categorical_accuracy: 0.7639 - val_top_3_accuracy: 0.8868\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
      "\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.76441\n",
      "Epoch 59/150\n",
      "5175/5174 [==============================] - 1264s 244ms/step - loss: 1.0649 - categorical_crossentropy: 1.0649 - categorical_accuracy: 0.7535 - top_3_accuracy: 0.8823 - val_loss: 1.0278 - val_categorical_crossentropy: 1.0278 - val_categorical_accuracy: 0.7638 - val_top_3_accuracy: 0.8871\n",
      "\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.76441\n",
      "Epoch 60/150\n",
      "5175/5174 [==============================] - 1262s 244ms/step - loss: 1.0608 - categorical_crossentropy: 1.0608 - categorical_accuracy: 0.7548 - top_3_accuracy: 0.8824 - val_loss: 1.0269 - val_categorical_crossentropy: 1.0269 - val_categorical_accuracy: 0.7643 - val_top_3_accuracy: 0.8873\n",
      "\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.76441\n",
      "Epoch 61/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3546/5174 [===================>..........] - ETA: 6:23 - loss: 1.0610 - categorical_crossentropy: 1.0610 - categorical_accuracy: 0.7552 - top_3_accuracy: 0.8828"
     ]
    }
   ],
   "source": [
    "model_prefix = 'xception{}_lw{}'.format(size, lw)\n",
    "callbks = [\n",
    "    ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5,\n",
    "                      min_delta=0.005, mode='max', cooldown=3, verbose=1),\n",
    "    callbacks.ModelCheckpoint(\"./models/{}.model\".format(model_prefix),\n",
    "                                monitor='val_categorical_accuracy', \n",
    "                                mode = 'max', save_best_only=True, verbose=1),\n",
    "    callbacks.TensorBoard(log_dir='./log/{}'.format(model_prefix)),\n",
    "    EarlyStopping(monitor='val_categorical_accuracy', mode='max',patience=20, verbose=1)\n",
    "]\n",
    "\n",
    "model.load_weights('models/xception128_lw6128_9.model')\n",
    "\n",
    "hists = []\n",
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fold = 9\n",
    "snapshot = SnapshotCallbackBuilder(nb_epochs=EPOCHS,nb_snapshots=1, \n",
    "                                   size = size,\n",
    "                                   init_lr=1e-3, fold=fold)\n",
    "\n",
    "callbks = snapshot.get_callbacks(model_prefix = model_prefix)\n",
    "\n",
    "sgd = SGD(0.002, momentum=0.9, nesterov=True)\n",
    "sgd = NormalizedOptimizer(sgd, normalization='l2')\n",
    "\n",
    "model.compile(optimizer=sgd, loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = []\n",
    "hist = model.fit_generator(\n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_swa = ''\n",
    "try:\n",
    "    print('using swa weight model')\n",
    "    model.load_weights('./models/{}_swa_{}.model'.format(model_prefix, fold))\n",
    "    prefix_swa = 'swa'\n",
    "except:\n",
    "    model.load_weights('./models/{}_{}.model'.format(model_prefix, fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test_simplified.csv')\n",
    "test.head()\n",
    "x_test = df_to_image_array_xd(test, size, lw = lw, preprocess_input=preprocess_input)\n",
    "print(test.shape, x_test.shape)\n",
    "print('Test array memory {:.2f} GB'.format(x_test.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(x_test, batch_size=128, verbose=1)\n",
    "\n",
    "top3 = preds2catids(test_predictions)\n",
    "top3.head()\n",
    "top3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_classes = np.load('../input/classes.npy')\n",
    "id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(np_classes)}\n",
    "top3cats = top3.replace(id2cat)\n",
    "top3cats.head()\n",
    "top3cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\n",
    "submission = test[['key_id', 'word']]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_util\n",
    "kaggle_util.save_result(submission, \n",
    "                        '../result/{}{}.csv'.format(model_prefix, prefix_swa),  \n",
    "                        'quickdraw-doodle-recognition', \n",
    "                        send=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
