{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\" \n",
    "import ast\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import Model\n",
    "from keras import optimizers\n",
    "from keras.legacy import interfaces\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from data import *\n",
    "from keras_helper import *\n",
    "\n",
    "from keras.applications import NASNetLarge\n",
    "from keras.applications.nasnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOT = 49673580\n",
    "EPOCHS = 50\n",
    "size = 64\n",
    "batchsize = 128\n",
    "lw = 6\n",
    "channel = 1\n",
    "STEPS = TOT / EPOCHS / batchsize / 3\n",
    "NCATS = 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# base_model = MobileNet(input_shape=(size, size, 3), alpha=1., weights='imagenet', include_top=False)\n",
    "# x = base_model.output\n",
    "# # x = GlobalAveragePooling2D()(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(512)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(64)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Activation('relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# predictions = Dense(NCATS, activation='softmax')(x)\n",
    "\n",
    "# model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model = NASNetLarge(input_shape=(size, size, 1), weights=None, classes=NCATS)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.002), loss='categorical_crossentropy',\n",
    "              metrics=[categorical_crossentropy, categorical_accuracy, top_3_accuracy])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('../input/valid.csv')\n",
    "x_valid = df_to_image_array_xd(valid_df, size, lw=lw, preprocess_input=preprocess_input, channel=channel)\n",
    "y_valid = keras.utils.to_categorical(valid_df.word, num_classes=NCATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_valid.shape, y_valid.shape)\n",
    "print('Validation array memory {:.2f} GB'.format(x_valid.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image_generator_xd(size=size, batchsize=batchsize, lw=lw, \n",
    "                                   preprocess_input=preprocess_input,\n",
    "                                  channel=channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prefix = 'nasnetlarge_raw_head_{}_lw{}'.format(size, lw)\n",
    "fold = 9\n",
    "callbks = [\n",
    "    ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5, patience=5,\n",
    "                      min_delta=0.005, mode='max', cooldown=3, verbose=1),\n",
    "    callbacks.ModelCheckpoint(\"./models/{}.model\".format(model_prefix),\n",
    "                                monitor='val_categorical_accuracy', \n",
    "                                mode = 'max', save_best_only=True, verbose=1),\n",
    "    callbacks.TensorBoard(log_dir='./log/{}'.format(model_prefix)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = []\n",
    "hist = model.fit_generator(  \n",
    "    train_datagen, steps_per_epoch=STEPS, epochs=EPOCHS, verbose=1,\n",
    "    validation_data=(x_valid, y_valid),\n",
    "    callbacks = callbks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./models/{}.model'.format(model_prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/test_simplified.csv')\n",
    "test.head()\n",
    "x_test = df_to_image_array_xd(test, size, lw=lw, \n",
    "                              preprocess_input=preprocess_input,\n",
    "                             channel=channel)\n",
    "print(test.shape, x_test.shape)\n",
    "print('Test array memory {:.2f} GB'.format(x_test.nbytes / 1024.**3 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(x_test, batch_size=128, verbose=1)\n",
    "\n",
    "top3 = preds2catids(test_predictions)\n",
    "top3.head()\n",
    "top3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_classes = np.load('../input/classes.npy')\n",
    "id2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(np_classes)}\n",
    "top3cats = top3.replace(id2cat)\n",
    "top3cats.head()\n",
    "top3cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\n",
    "submission = test[['key_id', 'word']]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle_util\n",
    "kaggle_util.save_result(submission, \n",
    "                        '../result/{}.csv'.format(model_prefix), \n",
    "                        'quickdraw-doodle-recognition', \n",
    "                        send=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
